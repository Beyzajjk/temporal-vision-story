"""from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer
from PIL import Image
import torch
import openai

# ğŸ”§ OpenAI API anahtarÄ±nÄ± ayarla
openai.api_key = "token"

# ğŸ“¸ GÃ¶rsel altyapÄ± modeli (GÃ¶rselden cÃ¼mle Ã¼retimi)
model = VisionEncoderDecoderModel.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
processor = ViTImageProcessor.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
tokenizer = AutoTokenizer.from_pretrained("nlpconnect/vit-gpt2-image-captioning")

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

# ğŸ“· GÃ¶rseli aÃ§
image = Image.open("profesyonel-fotograf-cekimi-1.jpg").convert("RGB")

# ğŸ›ï¸ GÃ¶rseli modele uygun hale getir
pixel_values = processor(images=image, return_tensors="pt").pixel_values.to(device)

# ğŸ“ AÃ§Ä±klama Ã¼ret
output_ids = model.generate(pixel_values, max_length=16)

caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)

print("FotoÄŸraf aÃ§Ä±klamasÄ±:", caption)


# ğŸ§  Hikaye Ã¼retme fonksiyonu
def hikaye_olustur(kullanici_cumlesi):
    prompt = f"'{kullanici_cumlesi}' cÃ¼mlesine dayalÄ± yaratÄ±cÄ± ve kÄ±sa bir hikaye oluÅŸtur."

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Sen yaratÄ±cÄ± bir hikaye anlatÄ±cÄ±sÄ±sÄ±n."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=400,
            temperature=0.8
        )

        hikaye = response.choices[0].message["content"]
        return hikaye

    except Exception as e:
        return f"Hata oluÅŸtu: {e}"


# ğŸ¬ Hikaye Ã¼ret
sonuc = hikaye_olustur(caption)

print("\n--- OluÅŸturulan Hikaye ---")
print(sonuc)
"""
"""
from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer
from PIL import Image
import torch
import requests
import json

# ğŸ“¸ GÃ¶rsel altyapÄ± modeli (GÃ¶rselden cÃ¼mle Ã¼retimi)
model = VisionEncoderDecoderModel.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
processor = ViTImageProcessor.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
tokenizer = AutoTokenizer.from_pretrained("nlpconnect/vit-gpt2-image-captioning")

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

# ğŸ“· GÃ¶rseli aÃ§
image = Image.open("profesyonel-fotograf-cekimi-1.jpg").convert("RGB")

# ğŸ›ï¸ GÃ¶rseli modele uygun hale getir
pixel_values = processor(images=image, return_tensors="pt").pixel_values.to(device)

# ğŸ“ AÃ§Ä±klama Ã¼ret
output_ids = model.generate(pixel_values, max_length=16)
caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)
print("FotoÄŸraf aÃ§Ä±klamasÄ±:", caption)

# ğŸ§  DeepSeek API ayarlarÄ±
DEESEEK_API_KEY = "token"
DEESEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"

# ğŸ§  Hikaye Ã¼retme fonksiyonu
def hikaye_olustur(cumle):
    prompt = f"'{cumle}' cÃ¼mlesine dayalÄ± yaratÄ±cÄ± ve kÄ±sa bir hikaye oluÅŸtur."

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEESEEK_API_KEY}"
    }

    data = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": "Sen yaratÄ±cÄ± bir hikaye anlatÄ±cÄ±sÄ±sÄ±n."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.8,
        "max_tokens": 400
    }

    try:
        response = requests.post(DEESEEK_API_URL, headers=headers, data=json.dumps(data))
        response.raise_for_status()
        hikaye = response.json()["choices"][0]["message"]["content"]
        return hikaye

    except Exception as e:
        return f"Hata oluÅŸtu: {e}"

# ğŸ¬ Hikaye Ã¼ret
sonuc = hikaye_olustur(caption)
print("\n--- OluÅŸturulan Hikaye ---")
print(sonuc)
"""
from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer, pipeline
from PIL import Image
import torch

# Cihaz ayarÄ± (GPU varsa kullan)
device = "cuda" if torch.cuda.is_available() else "cpu"

# 1) GÃ¶rselden aÃ§Ä±klama Ã¼retme modeli yÃ¼kle
model = VisionEncoderDecoderModel.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
processor = ViTImageProcessor.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
tokenizer = AutoTokenizer.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
model.to(device)

# GÃ¶rseli aÃ§
image = Image.open("wp2123042.jpg").convert("RGB")

# GÃ¶rseli modele uygun hale getir
pixel_values = processor(images=image, return_tensors="pt").pixel_values.to(device)

# AÃ§Ä±klama Ã¼ret
output_ids = model.generate(pixel_values, max_length=16)
caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)

print("FotoÄŸraf aÃ§Ä±klamasÄ±:", caption)


# 2) GPT-2 ile hikaye oluÅŸturma (text-generation pipeline)
story_generator = pipeline('text-generation', model='gpt2', device=0 if device=="cuda" else -1)

# Prompt oluÅŸtur (caption'a dayalÄ± kÄ±sa hikaye)
prompt = f"creative story based on this sentence: '{caption}'"

# Hikaye Ã¼ret
stories = story_generator(prompt, max_length=500, num_return_sequences=1)

print("\n--- OluÅŸturulan Hikaye ---")
print(stories[0]['generated_text'])
